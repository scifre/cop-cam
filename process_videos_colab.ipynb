{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CCTV Video Processing - Google Colab\n",
        "\n",
        "This notebook processes CCTV videos to detect and recognize people using YOLO and InsightFace.\n",
        "\n",
        "## Setup Instructions:\n",
        "1. **Upload your videos folder** - Run the upload cell below\n",
        "2. **Upload new_photos folder** (optional) - To build face recognition database\n",
        "   - Structure: `new_photos/person_name/image1.jpg, image2.jpg, ...`\n",
        "   - Example: `new_photos/ayush/ayush-1.jpg`\n",
        "3. **Or upload face_db folder** (alternative) - If you already have a face database\n",
        "4. **Run all cells** - Execute cells sequentially\n",
        "\n",
        "## What this notebook does:\n",
        "- Creates face recognition database from photos (if new_photos provided)\n",
        "- Detects people in videos using YOLO\n",
        "- Recognizes faces using InsightFace\n",
        "- Tracks people across frames\n",
        "- Generates annotated videos and detection JSON files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install -q opencv-python torch torchvision insightface deep-sort-realtime numpy pillow lancedb pyarrow ultralytics onnxruntime onnxruntime-gpu\n",
        "\n",
        "print(\"‚úì Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Upload Videos Folder\n",
        "\n",
        "Upload your videos folder. The folder should contain video files (e.g., `.mp4`, `.avi`, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"cctv_videos\", exist_ok=True)\n",
        "os.makedirs(\"face_db\", exist_ok=True)\n",
        "os.makedirs(\"processed_data/videos\", exist_ok=True)\n",
        "os.makedirs(\"processed_data/individual\", exist_ok=True)\n",
        "\n",
        "print(\"üìÅ Directories created!\")\n",
        "print(\"\\nüì§ Now upload your videos folder:\")\n",
        "print(\"   Option 1: Upload a zip file containing your videos\")\n",
        "print(\"   Option 2: Upload individual video files\")\n",
        "print(\"\\nüí° Tip: You can also upload face_db folder if you have one\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1b: Upload Face Photos (Optional)\n",
        "\n",
        "Upload your `new_photos` folder to build the face recognition database.  \n",
        "**Structure**: `new_photos/person_name/image1.jpg, image2.jpg, ...`\n",
        "\n",
        "Example:\n",
        "- `new_photos/ayush/ayush-1.jpg`\n",
        "- `new_photos/kanika/kanika-1.jpg`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload new_photos folder (zip file)\n",
        "os.makedirs(\"new_photos\", exist_ok=True)\n",
        "\n",
        "print(\"üì§ Upload new_photos folder:\")\n",
        "print(\"   Option 1: Upload a zip file containing new_photos folder\")\n",
        "print(\"   Option 2: Skip this step if you already have face_db folder\")\n",
        "print()\n",
        "\n",
        "uploaded_photos = files.upload()\n",
        "\n",
        "# Extract new_photos if uploaded\n",
        "for filename in uploaded_photos.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"üì¶ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            # Check if it contains new_photos folder\n",
        "            if any('new_photos' in f for f in zip_ref.namelist()):\n",
        "                zip_ref.extractall(\".\")\n",
        "                print(f\"‚úì Extracted new_photos folder\")\n",
        "            else:\n",
        "                # Extract to new_photos directory\n",
        "                zip_ref.extractall(\"new_photos\")\n",
        "                print(f\"‚úì Extracted to new_photos/\")\n",
        "\n",
        "# List uploaded photos\n",
        "new_photos_path = Path(\"new_photos\")\n",
        "if new_photos_path.exists():\n",
        "    person_dirs = [d for d in new_photos_path.iterdir() if d.is_dir()]\n",
        "    if person_dirs:\n",
        "        print(f\"\\nüì∏ Found {len(person_dirs)} person folder(s):\")\n",
        "        for person_dir in sorted(person_dirs):\n",
        "            image_files = list(person_dir.glob(\"*.jpg\")) + list(person_dir.glob(\"*.jpeg\")) + list(person_dir.glob(\"*.png\"))\n",
        "            print(f\"   - {person_dir.name}/ ({len(image_files)} images)\")\n",
        "    else:\n",
        "        print(\"\\n‚ö† No person folders found in new_photos/\")\n",
        "        print(\"   Expected structure: new_photos/person_name/image1.jpg\")\n",
        "else:\n",
        "    print(\"\\n‚ö† new_photos folder not found\")\n",
        "    print(\"   You can skip face recognition or upload face_db folder instead\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1c: Create Face Database from Photos\n",
        "\n",
        "This will process the uploaded photos and create/update the face database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import lancedb\n",
        "from pathlib import Path\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "def process_image_for_database(image_path, person_name, app):\n",
        "    \"\"\"Process a single image and return embedding with label\"\"\"\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Detect faces using InsightFace\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "    \n",
        "    # Use first face found\n",
        "    face = faces[0]\n",
        "    embedding = face.embedding  # 512-dimensional embedding\n",
        "    \n",
        "    return {\n",
        "        \"label\": person_name,\n",
        "        \"embedding\": np.asarray(embedding, dtype=np.float32).flatten()\n",
        "    }\n",
        "\n",
        "def populate_face_database(new_photos_dir=\"new_photos\"):\n",
        "    \"\"\"Process all images in new_photos and add to database\"\"\"\n",
        "    new_photos_path = Path(new_photos_dir)\n",
        "    \n",
        "    if not new_photos_path.exists():\n",
        "        print(f\"‚ö† {new_photos_dir} folder not found. Skipping face database creation.\")\n",
        "        print(\"   Face recognition will return 'unknown' for all faces.\")\n",
        "        return False\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PROCESSING FACE PHOTOS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Initialize InsightFace\n",
        "    print(\"Loading InsightFace model...\")\n",
        "    app = FaceAnalysis(providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"], \n",
        "                      allowed_modules=[\"detection\", \"recognition\"])\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    print(\"‚úì InsightFace loaded\")\n",
        "    \n",
        "    # Create or get face table\n",
        "    db = lancedb.connect(\"face_db\")\n",
        "    face_table = None\n",
        "    table_needs_creation = True\n",
        "    \n",
        "    try:\n",
        "        face_table = db.open_table(\"face_data\")\n",
        "        print(\"‚úì Opened existing face database\")\n",
        "        table_needs_creation = False\n",
        "    except:\n",
        "        print(\"üìù Will create new face database\")\n",
        "        table_needs_creation = True\n",
        "    \n",
        "    total_processed = 0\n",
        "    total_added = 0\n",
        "    total_failed = 0\n",
        "    \n",
        "    # Process each person's directory\n",
        "    person_dirs = [d for d in new_photos_path.iterdir() if d.is_dir()]\n",
        "    \n",
        "    if not person_dirs:\n",
        "        print(f\"‚ö† No person folders found in {new_photos_dir}/\")\n",
        "        return False\n",
        "    \n",
        "    all_embeddings = []  # Collect all embeddings first\n",
        "    \n",
        "    for person_dir in sorted(person_dirs):\n",
        "        person_name = person_dir.name\n",
        "        print(f\"\\nüë§ Processing: {person_name}/\")\n",
        "        \n",
        "        # Get all image files\n",
        "        image_files = []\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
        "            image_files.extend(person_dir.glob(ext))\n",
        "        \n",
        "        if len(image_files) == 0:\n",
        "            print(f\"  ‚ö† No images found\")\n",
        "            continue\n",
        "        \n",
        "        for image_path in sorted(image_files):\n",
        "            total_processed += 1\n",
        "            print(f\"  Processing: {image_path.name}...\", end=\" \")\n",
        "            \n",
        "            result = process_image_for_database(image_path, person_name, app)\n",
        "            \n",
        "            if result is None:\n",
        "                print(\"‚úó (no face detected)\")\n",
        "                total_failed += 1\n",
        "                continue\n",
        "            \n",
        "            all_embeddings.append(result)\n",
        "            print(\"‚úì\")\n",
        "    \n",
        "    # Create table with first batch or add to existing\n",
        "    if all_embeddings:\n",
        "        try:\n",
        "            if table_needs_creation:\n",
        "                # Create table with first batch\n",
        "                face_table = db.create_table(\"face_data\", all_embeddings, mode=\"overwrite\")\n",
        "                print(f\"\\n‚úì Created face database with {len(all_embeddings)} embeddings\")\n",
        "            else:\n",
        "                # Add to existing table\n",
        "                face_table.add(all_embeddings)\n",
        "                print(f\"\\n‚úì Added {len(all_embeddings)} embeddings to database\")\n",
        "            \n",
        "            total_added = len(all_embeddings)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚úó Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            total_failed = len(all_embeddings)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  Total images processed: {total_processed}\")\n",
        "    print(f\"  Successfully added: {total_added}\")\n",
        "    print(f\"  Failed: {total_failed}\")\n",
        "    \n",
        "    # Show database stats\n",
        "    try:\n",
        "        df = face_table.to_pandas()\n",
        "        print(f\"\\n  Database size: {len(df)} embeddings\")\n",
        "        print(f\"  Unique people: {df['label'].nunique()}\")\n",
        "        print(f\"  People: {', '.join(sorted(df['label'].unique()))}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n  Could not query database: {e}\")\n",
        "    \n",
        "    print(\"\\n‚úì Face database ready!\")\n",
        "    return True\n",
        "\n",
        "# Process photos if new_photos folder exists\n",
        "if Path(\"new_photos\").exists():\n",
        "    populate_face_database(\"new_photos\")\n",
        "else:\n",
        "    print(\"‚ö† Skipping face database creation (new_photos folder not found)\")\n",
        "    print(\"   You can upload face_db folder instead, or process videos without face recognition\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Helper Module\n",
        "\n",
        "This creates the helper.py file needed for face recognition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload videos (zip file or individual files)\n",
        "# If you upload a zip file, it will be extracted automatically\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract zip files if any\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"üì¶ Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            # Extract to cctv_videos if it's a videos folder\n",
        "            if 'video' in filename.lower() or any(f.endswith(('.mp4', '.avi', '.mov')) for f in zip_ref.namelist()):\n",
        "                zip_ref.extractall(\"cctv_videos\")\n",
        "                print(f\"‚úì Extracted videos to cctv_videos/\")\n",
        "            # Extract face_db if it's a face database\n",
        "            elif 'face' in filename.lower() or 'db' in filename.lower():\n",
        "                zip_ref.extractall(\"face_db\")\n",
        "                print(f\"‚úì Extracted face database to face_db/\")\n",
        "            else:\n",
        "                zip_ref.extractall(\".\")\n",
        "                print(f\"‚úì Extracted {filename} to current directory\")\n",
        "    elif filename.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "        # Move video files to cctv_videos\n",
        "        os.rename(filename, f\"cctv_videos/{filename}\")\n",
        "        print(f\"‚úì Moved {filename} to cctv_videos/\")\n",
        "\n",
        "# List uploaded videos\n",
        "video_files = list(Path(\"cctv_videos\").glob(\"*.*\"))\n",
        "video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv']\n",
        "video_files = [f for f in video_files if f.suffix.lower() in video_extensions]\n",
        "\n",
        "print(f\"\\nüìπ Found {len(video_files)} video file(s):\")\n",
        "for vf in video_files:\n",
        "    size_mb = vf.stat().st_size / (1024 * 1024)\n",
        "    print(f\"   - {vf.name} ({size_mb:.1f} MB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Helper Module\n",
        "\n",
        "This creates the helper.py file needed for face recognition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create helper.py\n",
        "helper_code = '''import numpy as np\n",
        "import torch\n",
        "import cv2  \n",
        "from torchvision import transforms\n",
        "from insightface.model_zoo import get_model\n",
        "from insightface.utils import face_align\n",
        "import torch.nn.functional as F\n",
        "import lancedb\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize LanceDB connection\n",
        "try:\n",
        "    db = lancedb.connect(\"face_db\")\n",
        "    face_table = db.open_table(\"face_data\")\n",
        "    print(\"‚úì Face database loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö† Warning: Could not load face database: {e}\")\n",
        "    print(\"   Face recognition will return 'unknown' for all faces\")\n",
        "    face_table = None\n",
        "\n",
        "def vector_search(embedding, threshold):\n",
        "    if embedding is None or face_table is None:\n",
        "        return (\"unknown\", float(\"inf\"))\n",
        "\n",
        "    emb = np.asarray(embedding, dtype=np.float32)\n",
        "    if emb.ndim != 1 or emb.shape[0] != 512:\n",
        "        return (\"unknown\", float(\"inf\"))\n",
        "\n",
        "    try:\n",
        "        res = (\n",
        "            face_table\n",
        "            .search(emb, vector_column_name=\"embedding\")\n",
        "            .metric(\"cosine\")\n",
        "            .select([\"label\", \"_distance\"])\n",
        "            .limit(1)\n",
        "            .to_list()\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return (\"unknown\", float(\"inf\"))\n",
        "\n",
        "    if not res:\n",
        "        return (\"unknown\", float(\"inf\"))\n",
        "\n",
        "    label = res[0][\"label\"]\n",
        "    dist = res[0][\"_distance\"]\n",
        "\n",
        "    if label is None or dist is None or dist >= threshold:\n",
        "        return (\"unknown\", dist)\n",
        "\n",
        "    return (label, dist)\n",
        "'''\n",
        "\n",
        "with open(\"helper.py\", \"w\") as f:\n",
        "    f.write(helper_code)\n",
        "\n",
        "print(\"‚úì helper.py created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Camera configuration\n",
        "# Update this to match your video files\n",
        "# Format: \"CAM_ID\": {\"name\": \"video_filename.mp4\", \"location\": {\"x\": 0.0, \"y\": 1.0, \"z\": 0.0}}\n",
        "\n",
        "CAMERA_CONFIG = {\n",
        "    \"CAM_01\": {\"name\": \"cp_lab1.mp4\", \"location\": {\"x\": 0.0, \"y\": 1.0, \"z\": 0.0}},\n",
        "    \"CAM_02\": {\"name\": \"cp_lab2.mp4\", \"location\": {\"x\": 0.866, \"y\": 0.5, \"z\": 0.0}},\n",
        "    \"CAM_03\": {\"name\": \"vlsi.mp4\", \"location\": {\"x\": 0.866, \"y\": -0.5, \"z\": 0.0}},\n",
        "    \"CAM_04\": {\"name\": \"iot.mp4\", \"location\": {\"x\": 0.0, \"y\": -1.0, \"z\": 0.0}},\n",
        "    \"CAM_05\": {\"name\": \"lift.mp4\", \"location\": {\"x\": -0.866, \"y\": -0.5, \"z\": 0.0}},\n",
        "    \"CAM_06\": {\"name\": \"loby.mp4\", \"location\": {\"x\": -0.866, \"y\": 0.5, \"z\": 0.0}},\n",
        "}\n",
        "\n",
        "# Auto-detect video files and create config\n",
        "from pathlib import Path\n",
        "video_dir = Path(\"cctv_videos\")\n",
        "video_files = list(video_dir.glob(\"*.mp4\")) + list(video_dir.glob(\"*.avi\")) + list(video_dir.glob(\"*.mov\"))\n",
        "\n",
        "if video_files:\n",
        "    print(\"üìπ Auto-detected video files:\")\n",
        "    auto_config = {}\n",
        "    for i, vf in enumerate(sorted(video_files), 1):\n",
        "        cam_id = f\"CAM_{i:02d}\"\n",
        "        auto_config[cam_id] = {\n",
        "            \"name\": vf.name,\n",
        "            \"location\": {\"x\": 0.0, \"y\": 1.0, \"z\": 0.0}  # Default location\n",
        "        }\n",
        "        print(f\"   {cam_id}: {vf.name}\")\n",
        "    \n",
        "    # Update CAMERA_CONFIG with auto-detected files\n",
        "    CAMERA_CONFIG = auto_config\n",
        "    print(f\"\\n‚úì Using auto-detected configuration with {len(CAMERA_CONFIG)} cameras\")\n",
        "else:\n",
        "    print(\"‚ö† No video files found. Using default CAMERA_CONFIG.\")\n",
        "    print(\"   Make sure your videos are in cctv_videos/ folder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize Models\n",
        "\n",
        "This will download and load YOLO and InsightFace models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "from insightface.app import FaceAnalysis\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from helper import vector_search\n",
        "\n",
        "# GPU setup\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "# Initialize models\n",
        "print(\"\\nüì• Loading models (this may take a few minutes on first run)...\")\n",
        "app = FaceAnalysis(providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"], \n",
        "                  allowed_modules=[\"detection\", \"recognition\"])\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "print(\"‚úì InsightFace loaded\")\n",
        "\n",
        "yolo_model = YOLO(\"yolov8m.pt\").to(device)\n",
        "print(\"‚úì YOLO loaded\")\n",
        "\n",
        "print(\"\\n‚úÖ All models ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Configure Processing Settings\n",
        "\n",
        "Adjust these settings based on your needs:\n",
        "- `FRAME_SKIP`: Process every Nth frame (higher = faster but less accurate)\n",
        "- `MAX_FRAMES`: Limit processing to first N frames (None = process all)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processing settings\n",
        "FRAME_SKIP = 2              # Process every Nth frame (2 = process every 2nd frame)\n",
        "ENABLE_GPU_CLEANUP = True   # Clear GPU cache periodically\n",
        "CLEANUP_INTERVAL = 50       # Clear GPU cache every N frames\n",
        "MAX_FRAMES = None           # Limit total frames (None = process all, set to number to limit)\n",
        "PAUSE_EVERY_N_FRAMES = 100  # Small pause every N frames (0 = no pause)\n",
        "PAUSE_DURATION = 0.1        # Pause duration in seconds\n",
        "\n",
        "# Directories\n",
        "VIDEO_DIR = \"cctv_videos\"\n",
        "OUTPUT_VIDEO_DIR = \"processed_data/videos\"\n",
        "OUTPUT_JSON = \"processed_data/detections.json\"\n",
        "INDIVIDUAL_JSON_DIR = \"processed_data/individual\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(OUTPUT_VIDEO_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)\n",
        "os.makedirs(INDIVIDUAL_JSON_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚öôÔ∏è  Processing settings:\")\n",
        "print(f\"   Frame skip: {FRAME_SKIP}\")\n",
        "print(f\"   Max frames: {MAX_FRAMES if MAX_FRAMES else 'All'}\")\n",
        "print(f\"   GPU cleanup: {'Enabled' if ENABLE_GPU_CLEANUP else 'Disabled'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Process Videos\n",
        "\n",
        "This will process all videos and generate annotated videos + detection JSON files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_video(cam_id, video_path, camera_config):\n",
        "    \"\"\"Process a single video\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {cam_id}: {video_path.name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error: Could not open video file {video_path}\")\n",
        "    \n",
        "    # Get video properties\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    print(f\"Resolution: {width}x{height}, FPS: {fps:.2f}, Frames: {total_frames}\")\n",
        "    \n",
        "    # Initialize tracker\n",
        "    tracker = DeepSort(max_age=40, max_cosine_distance=0.6, max_iou_distance=0.8)\n",
        "    \n",
        "    # Prediction dict\n",
        "    prediction_dict = defaultdict(lambda: {\n",
        "        \"name\": \"unknown\",\n",
        "        \"predictions\": []\n",
        "    })\n",
        "    \n",
        "    # Output video writer\n",
        "    output_video_path = os.path.join(OUTPUT_VIDEO_DIR, f\"{cam_id}.mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "    \n",
        "    # Store all detections\n",
        "    all_detections = []\n",
        "    \n",
        "    frame_id = 0\n",
        "    processed_frame_count = 0\n",
        "    \n",
        "    print(f\"\\nProcessing...\")\n",
        "    \n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # Frame skipping\n",
        "        if frame_id % FRAME_SKIP != 0:\n",
        "            frame_id += 1\n",
        "            out.write(frame)\n",
        "            continue\n",
        "        \n",
        "        # Limit total frames\n",
        "        if MAX_FRAMES and processed_frame_count >= MAX_FRAMES:\n",
        "            print(f\"\\n‚ö† Reached MAX_FRAMES limit ({MAX_FRAMES})\")\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                out.write(frame)\n",
        "            break\n",
        "        \n",
        "        clean_frame = frame.copy()\n",
        "        timestamp = frame_id / fps if fps > 0 else 0.0\n",
        "        \n",
        "        # YOLO detection\n",
        "        persons = yolo_model(frame)[0]\n",
        "        \n",
        "        identities = []\n",
        "        for person in persons.boxes:\n",
        "            if int(person.cls[0]) == 0:  # Class 0 = person\n",
        "                x1, y1, x2, y2 = map(int, person.xyxy[0])\n",
        "                conf = person.conf[0].cpu().numpy()\n",
        "                identities.append(([x1, y1, x2 - x1, y2 - y1], conf))\n",
        "        \n",
        "        # Update tracker\n",
        "        tracks = tracker.update_tracks(identities, frame=frame)\n",
        "        \n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            \n",
        "            track_id = track.track_id\n",
        "            name = prediction_dict[track_id][\"name\"]\n",
        "            score = track.get_det_conf()\n",
        "            \n",
        "            # Get bounding box\n",
        "            t, l, b, r = map(int, track.to_tlbr())\n",
        "            \n",
        "            # Face recognition for unknown persons\n",
        "            if name == \"unknown\":\n",
        "                person_crop = clean_frame[t:b, l:r]\n",
        "                if person_crop.size != 0:\n",
        "                    faces = app.get(person_crop)\n",
        "                    if len(faces) != 0:\n",
        "                        face = faces[0]\n",
        "                        embedding = face.embedding\n",
        "                        identity_results = vector_search(embedding, threshold=0.80)\n",
        "                        name, rec_score = identity_results\n",
        "                        rec_score = float(rec_score)\n",
        "                        prediction_dict[track_id][\"name\"] = name\n",
        "                        \n",
        "                        # Red box for newly identified\n",
        "                        cv2.rectangle(frame, (l, t), (r, b), (255, 0, 0), 2)\n",
        "                        cv2.putText(frame, f\"{name}-{rec_score:.2f}\", (l, t - 10), \n",
        "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "                        \n",
        "                        # Store detection\n",
        "                        detection = {\n",
        "                            \"timestamp\": round(timestamp, 3),\n",
        "                            \"frame_id\": frame_id,\n",
        "                            \"camera_id\": cam_id,\n",
        "                            \"track_id\": track_id,\n",
        "                            \"person_id\": name,\n",
        "                            \"bbox\": [l, t, r, b],\n",
        "                            \"confidence\": round(float(rec_score), 4),\n",
        "                            \"detection_confidence\": round(float(score), 4) if score is not None else None\n",
        "                        }\n",
        "                        all_detections.append(detection)\n",
        "            else:\n",
        "                # Yellow box for already identified\n",
        "                cv2.rectangle(frame, (l, t), (r, b), (0, 255, 255), 2)\n",
        "                if score is not None:\n",
        "                    cv2.putText(frame, f\"{name}-{score:.2f}\", (l, t - 10), \n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "                else:\n",
        "                    cv2.putText(frame, f\"{name}\", (l, t - 10), \n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "                \n",
        "                # Store detection\n",
        "                detection = {\n",
        "                    \"timestamp\": round(timestamp, 3),\n",
        "                    \"frame_id\": frame_id,\n",
        "                    \"camera_id\": cam_id,\n",
        "                    \"track_id\": track_id,\n",
        "                    \"person_id\": name,\n",
        "                    \"bbox\": [l, t, r, b],\n",
        "                    \"confidence\": None,\n",
        "                    \"detection_confidence\": round(float(score), 4) if score is not None else None\n",
        "                }\n",
        "                all_detections.append(detection)\n",
        "        \n",
        "        # Write frame\n",
        "        out.write(frame)\n",
        "        frame_id += 1\n",
        "        processed_frame_count += 1\n",
        "        \n",
        "        # GPU cleanup\n",
        "        if ENABLE_GPU_CLEANUP and processed_frame_count % CLEANUP_INTERVAL == 0:\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "        \n",
        "        # Pause\n",
        "        if PAUSE_EVERY_N_FRAMES > 0 and processed_frame_count % PAUSE_EVERY_N_FRAMES == 0:\n",
        "            time.sleep(PAUSE_DURATION)\n",
        "        \n",
        "        # Progress update\n",
        "        if processed_frame_count % 50 == 0:\n",
        "            progress = (frame_id / total_frames * 100) if total_frames > 0 else 0\n",
        "            print(f\"  Progress: Frame {frame_id}/{total_frames} ({progress:.1f}%) | Detections: {len(all_detections)}\")\n",
        "    \n",
        "    cap.release()\n",
        "    out.release()\n",
        "    \n",
        "    # Final cleanup\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    print(f\"\\n‚úì Completed {cam_id}:\")\n",
        "    print(f\"   Total frames: {frame_id}\")\n",
        "    print(f\"   Processed frames: {processed_frame_count}\")\n",
        "    print(f\"   Detections: {len(all_detections)}\")\n",
        "    print(f\"   Output video: {output_video_path}\")\n",
        "    \n",
        "    return all_detections, output_video_path\n",
        "\n",
        "print(\"‚úì Processing function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all videos\n",
        "all_detections = []\n",
        "camera_metadata = {}\n",
        "\n",
        "for cam_id, config in sorted(CAMERA_CONFIG.items()):\n",
        "    video_path = Path(VIDEO_DIR) / config[\"name\"]\n",
        "    \n",
        "    if not video_path.exists():\n",
        "        print(f\"‚ö† Warning: {video_path} not found, skipping {cam_id}\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        detections, output_path = process_video(cam_id, video_path, config)\n",
        "        all_detections.extend(detections)\n",
        "        \n",
        "        # Store camera metadata\n",
        "        camera_metadata[cam_id] = {\n",
        "            \"video_file\": config[\"name\"],\n",
        "            \"output_video\": f\"videos/{cam_id}.mp4\",\n",
        "            \"location\": config[\"location\"]\n",
        "        }\n",
        "        \n",
        "        # Save individual JSON\n",
        "        individual_data = {\n",
        "            \"camera_id\": cam_id,\n",
        "            \"metadata\": {\n",
        "                \"total_detections\": len(detections),\n",
        "                \"camera\": camera_metadata[cam_id]\n",
        "            },\n",
        "            \"detections\": detections\n",
        "        }\n",
        "        \n",
        "        individual_json_path = os.path.join(INDIVIDUAL_JSON_DIR, f\"{cam_id}.json\")\n",
        "        with open(individual_json_path, 'w') as f:\n",
        "            json.dump(individual_data, f, indent=2)\n",
        "        \n",
        "        print(f\"‚úì Saved individual results: {individual_json_path}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {cam_id}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"PROCESSING COMPLETE\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate Final Results\n",
        "\n",
        "Merge all detections into a single JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort all detections globally by timestamp\n",
        "all_detections.sort(key=lambda x: (x[\"timestamp\"], x[\"camera_id\"], x[\"frame_id\"]))\n",
        "\n",
        "# Create final output structure\n",
        "output_data = {\n",
        "    \"metadata\": {\n",
        "        \"total_detections\": len(all_detections),\n",
        "        \"total_cameras\": len(camera_metadata),\n",
        "        \"cameras\": camera_metadata\n",
        "    },\n",
        "    \"detections\": all_detections\n",
        "}\n",
        "\n",
        "# Save JSON\n",
        "with open(OUTPUT_JSON, 'w') as f:\n",
        "    json.dump(output_data, f, indent=2)\n",
        "\n",
        "print(f\"‚úì Saved {len(all_detections)} detections from {len(camera_metadata)} cameras\")\n",
        "print(f\"‚úì Output saved to: {OUTPUT_JSON}\")\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total detections: {len(all_detections)}\")\n",
        "\n",
        "# Count by person\n",
        "person_counts = defaultdict(int)\n",
        "for det in all_detections:\n",
        "    person_counts[det[\"person_id\"]] += 1\n",
        "\n",
        "print(f\"\\nDetections by person:\")\n",
        "for person, count in sorted(person_counts.items()):\n",
        "    print(f\"  {person}: {count}\")\n",
        "\n",
        "# Count by camera\n",
        "camera_counts = defaultdict(int)\n",
        "for det in all_detections:\n",
        "    camera_counts[det[\"camera_id\"]] += 1\n",
        "\n",
        "print(f\"\\nDetections by camera:\")\n",
        "for camera, count in sorted(camera_counts.items()):\n",
        "    print(f\"  {camera}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Download Results\n",
        "\n",
        "Download the processed videos and detection JSON files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zip file with all results\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "zip_filename = \"processed_results.zip\"\n",
        "\n",
        "print(\"üì¶ Creating results zip file...\")\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Add detection JSON\n",
        "    if os.path.exists(OUTPUT_JSON):\n",
        "        zipf.write(OUTPUT_JSON, \"detections.json\")\n",
        "        print(f\"‚úì Added detections.json\")\n",
        "    \n",
        "    # Add individual JSON files\n",
        "    individual_dir = Path(INDIVIDUAL_JSON_DIR)\n",
        "    for json_file in individual_dir.glob(\"*.json\"):\n",
        "        zipf.write(json_file, f\"individual/{json_file.name}\")\n",
        "        print(f\"‚úì Added {json_file.name}\")\n",
        "    \n",
        "    # Add processed videos\n",
        "    video_dir = Path(OUTPUT_VIDEO_DIR)\n",
        "    for video_file in video_dir.glob(\"*.mp4\"):\n",
        "        zipf.write(video_file, f\"videos/{video_file.name}\")\n",
        "        print(f\"‚úì Added {video_file.name}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Results zip created: {zip_filename}\")\n",
        "print(f\"üì• File size: {os.path.getsize(zip_filename) / (1024*1024):.1f} MB\")\n",
        "print(\"\\n‚¨áÔ∏è  Downloading results...\")\n",
        "files.download(zip_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally download individual files\n",
        "print(\"\\nüì• Individual file downloads:\")\n",
        "print(\"   Run the cell below to download specific files\")\n",
        "\n",
        "# Uncomment to download individual files:\n",
        "# files.download(OUTPUT_JSON)  # Download detections.json\n",
        "# files.download(\"processed_data/videos/CAM_01.mp4\")  # Download specific video\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
